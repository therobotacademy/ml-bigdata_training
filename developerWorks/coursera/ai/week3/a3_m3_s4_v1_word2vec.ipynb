{"nbformat_minor": 1, "cells": [{"source": "import numpy as np\nnp.random.seed(1)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Flatten, Input\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.optimizers import Adam\nfrom sklearn.preprocessing import OneHotEncoder\n", "cell_type": "code", "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"}], "metadata": {}}, {"source": "# define documents\ndocs = ['king is man',\n'a king marrys queen',\n'a queen marrys king',\n'some unrelated workds'\n'queen is woman']\ndocs", "cell_type": "code", "execution_count": 2, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "['king is man',\n 'a king marrys queen',\n 'a queen marrys king',\n 'some unrelated workdsqueen is woman']"}, "execution_count": 2}], "metadata": {}}, {"source": "vocab_size = 50", "cell_type": "code", "execution_count": 14, "outputs": [], "metadata": {}}, {"source": "oh = np.array(one_hot('king queen man woman unrelated', vocab_size)).reshape(-1,1)\noh", "cell_type": "code", "execution_count": 15, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[23],\n       [25],\n       [22],\n       [ 6],\n       [34]])"}, "execution_count": 15}], "metadata": {}}, {"source": "enc = OneHotEncoder()\nenc.fit(np.array(range(50)).reshape(-1,1))\noh_enc = enc.transform(oh).toarray()\noh_enc", "cell_type": "code", "execution_count": 16, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.]])"}, "execution_count": 16}], "metadata": {}}, {"source": "encoded_docs = [one_hot(d, vocab_size) for d in docs]\nencoded_docs ", "cell_type": "code", "execution_count": 17, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[[23, 42, 22], [12, 23, 35, 25], [12, 25, 35, 23], [16, 34, 12, 42, 6]]"}, "execution_count": 17}], "metadata": {}}, {"source": "max_length = 24\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\npadded_docs ", "cell_type": "code", "execution_count": 18, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[23, 42, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0],\n       [12, 23, 35, 25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0],\n       [12, 25, 35, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0],\n       [16, 34, 12, 42,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)"}, "execution_count": 18}], "metadata": {}}, {"source": "tuples = np.empty((0, 2))\nfor padded_doc in padded_docs:\n    length = len(padded_doc)\n    for i in range(length):\n        if padded_doc[i] <> 0:\n            if i<length-1 & padded_doc[i+1] <> 0:\n                tuples = np.append(tuples, [[padded_doc[i],padded_doc[i+1]]], axis=0) \n                if i<length-2 & padded_doc[i+2] <> 0:\n                    tuples = np.append(tuples, [[padded_doc[i],padded_doc[i+2]]], axis=0) \n            if i > 0:\n                tuples = np.append(tuples, [[padded_doc[i],padded_doc[i-1]]], axis=0) \n                if i > 1:\n                    tuples = np.append(tuples, [[padded_doc[i],padded_doc[i-2]]], axis=0) \n\n    \nprint tuples.shape\ntuples\n\n", "cell_type": "code", "execution_count": 19, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(38, 2)\n"}, {"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[23., 42.],\n       [23., 22.],\n       [42., 22.],\n       [42., 23.],\n       [22., 42.],\n       [22., 23.],\n       [12., 23.],\n       [12., 35.],\n       [23., 35.],\n       [23., 25.],\n       [23., 12.],\n       [35., 25.],\n       [35., 23.],\n       [35., 12.],\n       [25., 35.],\n       [25., 23.],\n       [12., 25.],\n       [12., 35.],\n       [25., 35.],\n       [25., 23.],\n       [25., 12.],\n       [35., 23.],\n       [35., 25.],\n       [35., 12.],\n       [23., 35.],\n       [23., 25.],\n       [16., 34.],\n       [16., 12.],\n       [34., 12.],\n       [34., 42.],\n       [34., 16.],\n       [12., 34.],\n       [12., 16.],\n       [42.,  6.],\n       [42., 12.],\n       [42., 34.],\n       [ 6., 42.],\n       [ 6., 12.]])"}, "execution_count": 19}], "metadata": {}}, {"source": "onehotlabels_x = enc.transform(tuples[:,0].reshape(-1, 1)).toarray()\n\nprint  onehotlabels_x.shape\nprint '---'\nprint onehotlabels_x\nprint '---'\nprint onehotlabels_x[0]", "cell_type": "code", "execution_count": 20, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(38, 50)\n---\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n---\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0.]\n"}], "metadata": {}}, {"source": "onehotlabels_y = enc.transform(tuples[:,1].reshape(-1, 1)).toarray()\n\nprint  onehotlabels_y.shape\nprint '---'\nprint onehotlabels_y\nprint '---'\nprint onehotlabels_y[0]", "cell_type": "code", "execution_count": 21, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(38, 50)\n---\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n---\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n 0. 0.]\n"}], "metadata": {}}, {"source": "model = Sequential()\n\ninput = Dense(50, input_shape=(50,), activation='relu')\nmodel.add(input)\nbottleneck = Dense(2, activation='relu')\nmodel.add(bottleneck)\nmodel.add(Dense(50, activation='softmax'))\n# compile the model\nmodel.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['acc'])\n# summarize the model\nprint(model.summary())\n\n# fit the model\nmodel.fit(onehotlabels_x, onehotlabels_y, epochs=500, verbose=1)", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "model = Sequential()\nmodel.add(input)\nmodel.add(bottleneck)\nmodel.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc'])\ntest = model.predict(oh_enc)\nprint test\n", "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[ 4.8148527  5.2279353]\n [10.759867   7.5104537]\n [ 5.034322   8.897757 ]\n [ 4.0494266 13.490577 ]\n [ 1.3467226  9.245243 ]]\n"}], "metadata": {}}, {"source": "model = Sequential()\nmodel.add(Embedding(1000, 2, input_length=5))\nmodel.compile('rmsprop', 'mse')\n\ninput_array = np.random.randint(1000, size=(12, 5)) # 12 documents, 5 words per document\ninput_array\n", "cell_type": "code", "execution_count": 33, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "array([[658, 953,  83, 215, 370],\n       [664, 385, 977, 952, 446],\n       [  5, 236, 489, 786, 190],\n       [975, 863,  75, 367,  38],\n       [693, 791, 151, 584, 615],\n       [556, 246, 617, 900, 774],\n       [895, 972,  77, 148, 818],\n       [831, 950, 312, 873, 851],\n       [642, 168, 390, 602, 753],\n       [382, 338, 305, 612, 338],\n       [198, 619, 421, 773, 513],\n       [745, 687, 348, 791, 761]])"}, "execution_count": 33}], "metadata": {}}, {"source": "\noutput_array = model.predict(input_array)\nprint output_array.shape\nprint output_array", "cell_type": "code", "execution_count": 34, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(12, 5, 2)\n[[[-0.00737526 -0.03952711]\n  [ 0.03562423 -0.00054917]\n  [ 0.02312161  0.01818525]\n  [-0.00454276  0.04821238]\n  [-0.04863647  0.02784937]]\n\n [[ 0.04942006  0.02649948]\n  [-0.03221387  0.0339553 ]\n  [-0.02424309 -0.00664258]\n  [ 0.03481558 -0.0233326 ]\n  [-0.02732114  0.04956144]]\n\n [[-0.00534445  0.04796547]\n  [ 0.02785101  0.01398841]\n  [ 0.02770859 -0.0203185 ]\n  [ 0.01846734  0.04200679]\n  [ 0.01816216 -0.03800594]]\n\n [[-0.00585238  0.0450164 ]\n  [ 0.04364623 -0.03347833]\n  [ 0.01359291 -0.03891221]\n  [-0.03987021 -0.0218769 ]\n  [ 0.00964461  0.04767007]]\n\n [[ 0.04616523  0.04316676]\n  [-0.026916   -0.03370332]\n  [-0.00778913  0.00687754]\n  [-0.03998027 -0.01103918]\n  [-0.00807313  0.02954686]]\n\n [[ 0.04351507 -0.04329052]\n  [ 0.04884141 -0.03043994]\n  [-0.01627801 -0.01220991]\n  [ 0.04792753 -0.01185318]\n  [ 0.02459591  0.02811902]]\n\n [[-0.04344755 -0.00232911]\n  [ 0.02211753  0.01849543]\n  [ 0.04227458 -0.04719234]\n  [-0.02551355 -0.02170448]\n  [ 0.01019226 -0.01790239]]\n\n [[ 0.00958564  0.02275202]\n  [ 0.03301926 -0.01803961]\n  [-0.04985998 -0.01354582]\n  [-0.03342386  0.04992533]\n  [ 0.04271096 -0.04566098]]\n\n [[-0.02910888 -0.02700466]\n  [ 0.02055869  0.01854159]\n  [ 0.00683111 -0.03330612]\n  [ 0.03122682 -0.00685179]\n  [ 0.04974637  0.01571622]]\n\n [[-0.02255743 -0.01989919]\n  [-0.01055164 -0.04046997]\n  [-0.03692471 -0.04345294]\n  [ 0.02828341 -0.0440641 ]\n  [-0.01055164 -0.04046997]]\n\n [[ 0.00269728 -0.03708148]\n  [ 0.02754216  0.01125765]\n  [ 0.0420585   0.01967246]\n  [-0.00545651 -0.00900711]\n  [ 0.02233386  0.00286186]]\n\n [[ 0.0465229   0.02601541]\n  [-0.01944144  0.00615913]\n  [-0.0177219   0.01166546]\n  [-0.026916   -0.03370332]\n  [-0.04163221 -0.00929393]]]\n"}], "metadata": {}}, {"source": "# define documents\ndocs = ['Well done!',\n'Good work',\n'Great effort',\n'nice work',\n'Excellent!',\n'Really Weak',\n'Poor effort!',\n'not good',\n'poor work',\n'Could have done better.']\n# define class labels\nlabels = [1,1,1,1,1,0,0,0,0,0]", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {}}, {"source": "# integer encode the documents\nvocab_size = 50\nencoded_docs = [one_hot(d, vocab_size) for d in docs]\nprint(encoded_docs)", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[4, 4], [48, 43], [26, 42], [36, 43], [47], [10, 6], [8, 42], [19, 48], [8, 43], [49, 30, 4, 49]]\n"}], "metadata": {}}, {"source": "# pad documents to a max length of 4 words\nmax_length = 4\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\nprint(padded_docs)", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[ 4  4  0  0]\n [48 43  0  0]\n [26 42  0  0]\n [36 43  0  0]\n [47  0  0  0]\n [10  6  0  0]\n [ 8 42  0  0]\n [19 48  0  0]\n [ 8 43  0  0]\n [49 30  4 49]]\n"}], "metadata": {}}, {"source": "model = Sequential()\nmodel.add(Embedding(vocab_size, 8, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n# summarize the model\nprint(model.summary())", "cell_type": "code", "execution_count": 7, "outputs": [{"output_type": "stream", "name": "stdout", "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 4, 8)              400       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 433\nTrainable params: 433\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"}], "metadata": {}}, {"source": "# fit the model\nmodel.fit(padded_docs, labels, epochs=50, verbose=0)\n# evaluate the model\nloss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))", "cell_type": "code", "execution_count": 45, "outputs": [{"output_type": "error", "evalue": "Input arrays should have the same number of samples as target arrays. Found 9 input samples and 10 target samples.", "traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-45-06cfc31c8474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/.local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n", "\u001b[0;32m/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1497\u001b[0;31m             \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1498\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1499\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/gpfs/fs01/user/se2e-1a118c4f322670-980ba6aaa6c3/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_check_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    218\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         raise ValueError('All sample_weight arrays should have '\n", "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 9 input samples and 10 target samples."], "ename": "ValueError"}], "metadata": {}}, {"source": "import numpy as np\nnp.hstack((model.predict(padded_docs),np.array(labels).reshape(10,1)))", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}
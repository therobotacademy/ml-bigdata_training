{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sensor_id=141, sensor_type=u'BME280', location=65, lat=48.779, lon=9.16, timestamp=datetime.datetime(2017, 6, 18, 0, 1, 33), pressure=99377.36, altitude=None, pressure_sealevel=None, temperature=20.65, humidity=61.46),\n",
       " Row(sensor_id=141, sensor_type=u'BME280', location=65, lat=48.779, lon=9.16, timestamp=datetime.datetime(2017, 6, 18, 0, 3, 59), pressure=99373.08, altitude=None, pressure_sealevel=None, temperature=20.63, humidity=61.32),\n",
       " Row(sensor_id=141, sensor_type=u'BME280', location=65, lat=48.779, lon=9.16, timestamp=datetime.datetime(2017, 6, 18, 0, 6, 25), pressure=99376.98, altitude=None, pressure_sealevel=None, temperature=20.58, humidity=61.55),\n",
       " Row(sensor_id=141, sensor_type=u'BME280', location=65, lat=48.779, lon=9.16, timestamp=datetime.datetime(2017, 6, 18, 0, 8, 51), pressure=99375.36, altitude=None, pressure_sealevel=None, temperature=20.62, humidity=60.92),\n",
       " Row(sensor_id=141, sensor_type=u'BME280', location=65, lat=48.779, lon=9.16, timestamp=datetime.datetime(2017, 6, 18, 0, 11, 17), pressure=99373.08, altitude=None, pressure_sealevel=None, temperature=20.69, humidity=60.88)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# @hidden_cell\n",
    "# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def set_hadoop_config_with_credentials_d3bd5b94a9334de59a55a7fed2bedeaa(name):\n",
    "    \"\"\"This function sets the Hadoop configuration so it is possible to\n",
    "    access data from Bluemix Object Storage using Spark\"\"\"\n",
    "\n",
    "    prefix = 'fs.swift.service.' + name\n",
    "    hconf = sc._jsc.hadoopConfiguration()\n",
    "    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n",
    "    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n",
    "    hconf.set(prefix + '.tenant', '6aaf54352357483486ee2d4981f8ef15')\n",
    "    hconf.set(prefix + '.username', '9033afb2dbf04d06948d8a4947fd7b27')\n",
    "    hconf.set(prefix + '.password', 'SB1oYs/1Jxt*ND*}')\n",
    "    hconf.setInt(prefix + '.http.port', 8080)\n",
    "    hconf.set(prefix + '.region', 'dallas')\n",
    "    hconf.setBoolean(prefix + '.public', False)\n",
    "\n",
    "# you can choose any name\n",
    "name = 'keystone'\n",
    "set_hadoop_config_with_credentials_d3bd5b94a9334de59a55a7fed2bedeaa(name)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df_data_1 = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema','true')\\\n",
    "  .option('delimiter',';')\\\n",
    "  .load('swift://fablab.' + name + '/2017-06-18_bme280_sensor_141.csv')\n",
    "df_data_1.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data_1.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sensor_id: integer (nullable = true)\n",
      " |-- sensor_type: string (nullable = true)\n",
      " |-- location: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- pressure: double (nullable = true)\n",
      " |-- altitude: string (nullable = true)\n",
      " |-- pressure_sealevel: string (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdata = spark.sql(\"select cast(timestamp as long),humidity,temperature,lat,lon from data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- humidity: double (nullable = true)\n",
      " |-- temperature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n",
      "Table VERSION_TRACKER created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-cds-labs/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-cds-labs/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.0.2</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table USER_PREFERENCES created successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>Warning: You are not running the latest version of PixieDust. Current is 1.0.2, Latest is 1.0.6</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>Please restart kernel after upgrading.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pixiedust": {
     "displayParams": {
      "aggregation": "MAX",
      "handlerId": "mapView",
      "keyFields": "timestamp",
      "rendererId": "matplotlib",
      "rowCount": "100",
      "valueFields": "temperature"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n",
       "        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n",
       "            \n",
       "        </div>\n",
       "    <div id=\"chartFigure96bc0fc2\" class=\"pd_save is-viewer-good\" style=\"overflow-x:auto\">\n",
       "            <div>\n",
       "    <h2>No Google Maps API Key</h2>\n",
       "    <p>\n",
       "        Some functionality of the Google maps renderer requires an API key.\n",
       "    </p>\n",
       "    <p>\n",
       "        You can obtain an API key from the <a href=\"https://code.google.com/apis/console/\" target=\"_blank\">Google API Console</a>.\n",
       "        After <a href=\"https://support.google.com/googleapi/answer/6158862?hl=en&amp;ref_topic=7013279\" target=\"_blank\">getting the API key</a>,\n",
       "        it must be enabled for the <a href=\"https://console.developers.google.com/projectselector/apis/library\" target=\"_blank\">Google Maps Javascript API and the Geocoding API</a>.\n",
       "        Once enabled, you may enter the API key in the Options dialog.\n",
       "    </p>\n",
       "</div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
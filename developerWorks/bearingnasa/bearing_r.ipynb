{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "setHadoopConfigWithCredentials_d3bd5b94a9334de59a55a7fed2bedeaa <- function(name) {\n",
    "    # This function sets the Hadoop configuration so it is possible to\n",
    "    # access data from Bluemix Object Storage using Spark\n",
    "\n",
    "    prefix = paste(\"fs.swift.service\" , name, sep =\".\")\n",
    "    hConf = SparkR:::callJMethod(sc, \"hadoopConfiguration\")\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"auth.url\", sep='.'), paste(\"https://identity.open.softlayer.com\",\"/v3/auth/tokens\",sep=\"\"))\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"auth.endpoint.prefix\", sep='.'), \"endpoints\")\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"tenant\", sep='.'), \"6aaf54352357483486ee2d4981f8ef15\")\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"username\", sep='.'), \"c0eebedc019f4413be3f3d656821b35f\")\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"password\", sep='.'), \"ji[T[l.(7D&gld*5\")\n",
    "    SparkR:::callJMethod(hConf, \"set\", paste(prefix, \"region\", sep='.'), \"dallas\")\n",
    "    invisible(SparkR:::callJMethod(hConf, \"setBoolean\", paste(prefix, \"public\", sep='.'), FALSE))\n",
    "}\n",
    "\n",
    "name <- \"keystone\"\n",
    "setHadoopConfigWithCredentials_d3bd5b94a9334de59a55a7fed2bedeaa(name)\n",
    "\n",
    "invisible(sparkR.session(appName = \"test SparkSession R\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.data.1 <- read.json(paste(\"swift://\", \"coursera\", \".\" , name,\"/\", \"bearing1_1_acc_transformed4.json\", sep=\"\"), \n",
    "                       source = \"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\", header = \"true\")\n",
    "head(df.data.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(df.data.1)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "createOrReplaceTempView(df.data.1,\"data\")\n",
    "df_sample = sql(\"select * from data where rand() <= .1 order by ts asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(df_sample)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_rdf = collect(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(df_sample_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_sample_rdf)\n",
    "plot(ts,hacc, type=\"o\", col=\"blue\")\n",
    "detach(df_sample_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_sample_rdf)\n",
    "plot(ts,vacc, type=\"o\", col=\"blue\")\n",
    "detach(df_sample_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_grouped = sql(\"\n",
    "    select cluster,\n",
    "    mean(hacc) as mhacc,\n",
    "    mean(vacc) as mvacc,\n",
    "    STDDEV_POP(hacc) as sdhacc,\n",
    "    STDDEV_POP(vacc) as sdvacc \n",
    "    from data \n",
    "    group by cluster \n",
    "    order by cluster asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_grouped_local = collect(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(df_grouped_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_grouped_local)\n",
    "plot(cluster,sdhacc)\n",
    "detach(df_grouped_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_grouped_local)\n",
    "plot(cluster,sdvacc)\n",
    "detach(df_grouped_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_grouped_local)\n",
    "plot(cluster,mhacc)\n",
    "detach(df_grouped_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df_grouped_local)\n",
    "plot(cluster,mvacc)\n",
    "detach(df_grouped_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install.packages(\"wavelets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(wavelets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(df_sample_rdf)\n",
    "wt = dwt(vacc, filter=\"haar\", boundary=\"periodic\")\n",
    "detach(df_sample_rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(unlist(c(wt@W,wt@V[[wt@level]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R with Spark 2.1",
   "language": "R",
   "name": "r-spark21"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

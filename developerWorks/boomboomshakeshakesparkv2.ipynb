{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please run the following cell once.\n",
    "\n",
    "This will install the Apache Bahir connector within your Project/Apache Spark service. If you restart the kernel or start a new notebook in the same project you can use Apache Bahir for connecting to the Cloudant/Apache CouchDB service. Please note that this will install a patched version of the connector (since the pull request hasn't been merged with the trunk yet).\n",
    "\n",
    "You'll find more information on the patch here:\n",
    "\n",
    "https://github.com/apache/bahir/pull/49 https://issues.apache.org/jira/browse/BAHIR-130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "pixiedust.installPackage(\"https://github.com/romeokienzler/developerWorks/raw/master/coursera/spark-sql-cloudant_2.11-2.3.0-SNAPSHOT.jar\")\n",
    "pixiedust.installPackage(\"com.typesafe:config:1.3.1\")\n",
    "pixiedust.installPackage(\"com.typesafe.play:play-json_2.11:jar:2.5.9\")\n",
    "pixiedust.installPackage(\"org.scalaj:scalaj-http_2.11:jar:2.3.0\")\n",
    "pixiedust.installPackage(\"com.typesafe.play:play-functional_2.11:jar:2.5.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PLEASE INSERT TO CREDENTIALS TO CLOUDANT HERE USING THE IBM WATSON STUDIO CONNECTIONS TAB RIGHT TO THIS NOTEBOOK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Cloudant Spark SQL Example in Python using temp tables\")\\\n",
    "    .config(\"cloudant.host\",credentials_1['custom_url'].split('@')[1])\\\n",
    "    .config(\"cloudant.username\", credentials_1['username'])\\\n",
    "    .config(\"cloudant.password\",credentials_1['password'])\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=spark.read.load('shake', 'org.apache.bahir.cloudant')\n",
    "df.createOrReplaceTempView('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select sqrt(sum(X*X)+sum(Y*Y)+sum(Z*Z)) as energy, SENSORID from data group by SENSORID order by energy desc\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 with Spark 2.1",
   "language": "python",
   "name": "python3-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
